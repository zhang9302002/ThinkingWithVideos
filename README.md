# Thinking With Videos: Multimodal Tool-Augmented Reinforcement Learning for Long Video Reasoning

<a href="https://zhang9302002.github.io/">Haoji Zhang</a><sup>\*</sup>,
<a href="https://gx77.github.io/GX/">Xin Gu</a><sup>\*</sup>,
Jiawen Li,
Chixiang Ma,
<a href="https://sulebai.github.io/">Sule Bai</a>,
<a href="https://lin-shan.com/">Chubin Zhang</a>,
Bowen Zhang,
Zhichao Zhou,
Dongliang He,
<a href="https://andytang15.github.io/">Yansong Tang</a><sup>&dagger;</sup>

<sup>\*</sup>Equal contributions, 
<sup>&dagger;</sup>Correspondence

<a href="https://zhang9302002.github.io/thinkingwithvideos-page/"><img src='https://img.shields.io/badge/Project-Page-Green'></a>
<a href="https://arxiv.org/abs/2508.04416"><img src='https://img.shields.io/badge/Paper-Arxiv-red'></a>
<a href="https://huggingface.co/datasets/zhang9302002/MultiTaskVideoReasoning"><img src='https://img.shields.io/badge/Data-Huggingface-yellow'></a>

We proposed **VITAL**, a tool-augmented framework that enables advanced long video reasoning and temporal grounding.

We also introduce **MTVR**, a high-quality multi-task video reasoning training dataset.

(Code is coming soon.)
